{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effectiveness of Random Oversampling\n",
    "\n",
    "In this activity, you’ll fit logistic regression models to both imbalanced data and resampled data. You’ll then compare the results by using the metrics that you’ve learned.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Read in the CSV file from the `Resources` folder into a Pandas DataFrame.  \n",
    "\n",
    "2. Create a Series named `y` that contains the data from the \"Default\" column of the original DataFrame. Note that this Series will contain the labels. Create a new DataFrame named `X` that contains the remaining columns from the original DataFrame. Note that this DataFrame will contain the features.\n",
    "\n",
    "3. Split the features and labels into training and testing sets.\n",
    "\n",
    "4. Check the magnitude of imbalance in the data set by viewing  the number of distinct values  (`value_counts`) for the labels. \n",
    "\n",
    "5. Resample the training data by using `RandomOverSampler`.\n",
    "\n",
    "6. Check the number of distinct values (`value_counts`) for the resampled labels.\n",
    "\n",
    "7. Fit two logistic regression modules: one for the resampled data and another for the original data.\n",
    "\n",
    " 8.  Using the two logistic regression models, predict the values for the original and resampled sets.\n",
    "\n",
    "9. Print the confusion matrixes, accuracy scores, and classification reports for the original and resampled datasets.\n",
    "\n",
    "10. Evaluate the effectiveness of random oversampling for predicting the minority class. Answer the following question: Does the model accurately flag all the loans that eventually defaulted?\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "Following are links to modules from the scikit learn library that will be utilized:\n",
    "\n",
    "[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "[confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "\n",
    "[balanced_accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html)\n",
    "\n",
    "Following are links to modules from the imbalanced learn library that will be utilized:\n",
    "\n",
    "[RandomOverSampler](https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.RandomOverSampler.html)\n",
    "\n",
    "[classifiction_report_imbalanced](https://imbalanced-learn.org/stable/generated/imblearn.metrics.classification_report_imbalanced.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in the CSV file from the `Resources` folder into a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Term</th>\n",
       "      <th>Zip</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>RealEstate</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>32812</td>\n",
       "      <td>36</td>\n",
       "      <td>92801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>56</td>\n",
       "      <td>90505</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>36</td>\n",
       "      <td>92103</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>36</td>\n",
       "      <td>92108</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>343000</td>\n",
       "      <td>240</td>\n",
       "      <td>91345</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Amount  Term    Zip  CreateJob  NoEmp  RealEstate  RevLineCr  \\\n",
       "0  2001     11   32812    36  92801          0      1           0          1   \n",
       "1  2001      4   30000    56  90505          0      1           0          1   \n",
       "2  2001      4   30000    36  92103          0     10           0          1   \n",
       "3  2003     10   50000    36  92108          0      6           0          1   \n",
       "4  2006      7  343000   240  91345          3     65           1          0   \n",
       "\n",
       "   UrbanRural  Default  \n",
       "0           0        0  \n",
       "1           0        0  \n",
       "2           0        0  \n",
       "3           0        0  \n",
       "4           2        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the sba_loans.csv file from the Resources folder into a Pandas DataFrame\n",
    "loans_df = pd.read_csv(\n",
    "    Path('../Resources/sba_loans.csv')\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a Series named `y` that contains the data from the \"Default\" column of the original DataFrame. Note that this Series will contain the labels. Create a new DataFrame named `X` that contains the remaining columns from the original DataFrame. Note that this DataFrame will contain the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X (features) and y (lables)\n",
    "\n",
    "# The y variable should focus on the Default column\n",
    "y = loans_df['Default']\n",
    "\n",
    "# The X variable should include all features except the Default column\n",
    "X = loans_df.drop(columns=['Default'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the features and labels into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check the magnitude of imbalance in the data set by viewing  the number of distinct values  (`value_counts`) for the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1063\n",
       "1      96\n",
       "Name: Default, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the distinct values in the orignal labels data\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Resample the training data by using `RandomOverSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data using RandomOverSampler\n",
    "\n",
    "# Use RandomOversampler to create a model\n",
    "# Set a random_state paramerter with a value of 1\n",
    "random_oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "X_resampled, y_resampled = random_oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Check the number of distinct values (`value_counts`) for the resampled labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1063\n",
       "0    1063\n",
       "Name: Default, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the distinct values in the resampled labels data\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Fit two logistic regression modules: one for the resampled data and another for the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a logistic regression model\n",
    "# Set a random_state paramerter with a value of 1\n",
    "model = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression for the original data.\n",
    "lr_orginal_model = model.fit(X_train, y_train)\n",
    "lr_orginal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a logistic regression model\n",
    "# Set a random_state paramerter with a value of 1\n",
    "model = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression for the resampled data\n",
    "lr_resampled_model = model.fit(X_resampled, y_resampled)\n",
    "lr_resampled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Using the two logistic regression models, predict the values for the original and resampled sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for testing features using the original logistic regression model\n",
    "y_original_pred = lr_orginal_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the testing features using the resampled logistic regression model\n",
    "y_resampled_pred = lr_resampled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Print the confusion matrixes, accuracy scores, and classification reports for the original and resampled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[343,   5],\n",
       "       [ 33,   6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix for the original data\n",
    "confusion_matrix(y_test, y_original_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[280,  68],\n",
       "       [  7,  32]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix for the resampled data\n",
    "confusion_matrix(y_test, y_resampled_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5697391688770999\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score for the original data\n",
    "baso = balanced_accuracy_score(y_test, y_original_pred)\n",
    "\n",
    "print(baso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125552608311228\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score for the resampled data\n",
    "basr = balanced_accuracy_score(y_test, y_resampled_pred)\n",
    "print(basr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.91      0.99      0.15      0.95      0.39      0.16       348\n",
      "          1       0.55      0.15      0.99      0.24      0.39      0.14        39\n",
      "\n",
      "avg / total       0.88      0.90      0.24      0.88      0.39      0.16       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the original data\n",
    "print(classification_report_imbalanced(y_test, y_original_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.80      0.82      0.88      0.81      0.66       348\n",
      "          1       0.32      0.82      0.80      0.46      0.81      0.66        39\n",
      "\n",
      "avg / total       0.91      0.81      0.82      0.84      0.81      0.66       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the resampled data\n",
    "print(classification_report_imbalanced(y_test, y_resampled_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate the effectiveness of random oversampling for predicting the minority class. Answer the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does the model generated using the resampled data more accurately flag all the loans that eventually defaulted?\n",
    "    \n",
    "**Answer:** The results regarding accuracy of the minority class are actually mixed when comparing the classifiction reports generated from the predictions with the original data versus the predictions with the resampled data. \n",
    "\n",
    "First, the accuracy score is much higher for the resampled data (0.81 vs 0.56), meaning that the model using resampled data was much better at detecting true positives and true negatives. \n",
    "\n",
    "The precision for the minority class is higher with the orignal data (0.55) versus the resampled data (0.32) meaning that the original data was better at detecting the users that were actually going to default. \n",
    "\n",
    "In terms of the recall, however, the minority class metric using resampled data was much better (0.82 vs 0.15). Meaning that the resampled data correctly clasified a higher percentage of the truly defaulting borrowers. \n",
    "\n",
    "All in, the model using resampled data was much better at detecting borrowers who are likely to default that the model generated using the original, imbalanced dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
